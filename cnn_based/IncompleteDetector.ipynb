{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e1dad5",
   "metadata": {},
   "source": [
    "## Installing OpenCV for Image Processing\n",
    "Installing opencv-python which provides computer vision functions for mask generation and image manipulation.\n",
    "OpenCV will be used for drawing shapes, applying masks, and basic image transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f645d2-6a7e-4608-878c-b62cb47114de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\skand\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\skand\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d0676b",
   "metadata": {},
   "source": [
    "## Import OpenCV for Image Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d675d8a",
   "metadata": {},
   "source": [
    "## Creating Synthetic Training Data\n",
    "This cell generates incomplete images from complete ones using various masking strategies (freeform, random patches, center blocks, irregular blobs).\n",
    "Creates both black-filled and white-filled versions to provide training diversity and robustness to different inpainting scenarios.\n",
    "Progress tracking with tqdm processes 1038 images to create the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253c0b69-f552-40f5-a1ca-75b41a4517ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1038/1038 [00:09<00:00, 113.66it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_mask(img_shape, mask_type='freeform'):\n",
    "    h, w = img_shape[:2]\n",
    "    mask = np.ones((h, w), dtype=np.uint8) * 255  # Start with white\n",
    "\n",
    "    if mask_type == 'center_block':\n",
    "        mask[h//4:h*3//4, w//4:w*3//4] = 0\n",
    "\n",
    "    elif mask_type == 'random_patches':\n",
    "        for _ in range(5):\n",
    "            x, y = random.randint(0, w//2), random.randint(0, h//2)\n",
    "            patch_w = random.randint(w//10, w//4)\n",
    "            patch_h = random.randint(h//10, h//4)\n",
    "            mask[y:y+patch_h, x:x+patch_w] = 0\n",
    "\n",
    "    elif mask_type == 'freeform':\n",
    "        for _ in range(random.randint(5, 15)):\n",
    "            x1, y1 = random.randint(0, w), random.randint(0, h)\n",
    "            angle = random.uniform(0, 2*np.pi)\n",
    "            length = random.randint(20, 100)\n",
    "            brush_w = random.randint(10, 30)\n",
    "            x2 = int(x1 + length * np.cos(angle))\n",
    "            y2 = int(y1 + length * np.sin(angle))\n",
    "            cv2.line(mask, (x1, y1), (x2, y2), 0, brush_w)\n",
    "\n",
    "    elif mask_type == 'irregular_blobs':\n",
    "        for _ in range(3):\n",
    "            center = (random.randint(0, w), random.randint(0, h))\n",
    "            axes = (random.randint(20, 60), random.randint(20, 60))\n",
    "            angle = random.randint(0, 360)\n",
    "            cv2.ellipse(mask, center, axes, angle, 0, 360, 0, -1)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def apply_mask_to_image(image, mask, fill_color='black'):\n",
    "    masked_image = image.copy()\n",
    "    if fill_color == 'black':\n",
    "        masked_image[mask == 0] = [0, 0, 0]\n",
    "    elif fill_color == 'white':\n",
    "        masked_image[mask == 0] = [255, 255, 255]\n",
    "    return masked_image\n",
    "\n",
    "def generate_incomplete_images(input_folder, black_output_folder, white_output_folder, mask_type='freeform'):\n",
    "    \n",
    "    for filename in tqdm(os.listdir(input_folder)):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')): continue\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            print(f\"Warning: Couldn't read image {filename}\")\n",
    "            continue\n",
    "\n",
    "        mask = generate_mask(image.shape, mask_type)\n",
    "\n",
    "        black_img = apply_mask_to_image(image, mask, fill_color='black')\n",
    "        white_img = apply_mask_to_image(image, mask, fill_color='white')\n",
    "\n",
    "        cv2.imwrite(os.path.join(black_output_folder, filename), black_img)\n",
    "        cv2.imwrite(os.path.join(white_output_folder, filename), white_img)\n",
    "\n",
    "# Example usage\n",
    "generate_incomplete_images(\n",
    "    input_folder=r\"C:\\Users\\skand\\Downloads\\2i\\complete\",\n",
    "    black_output_folder=r\"C:\\Users\\skand\\Downloads\\2i\\incomplete\\black\",\n",
    "    white_output_folder=r\"C:\\Users\\skand\\Downloads\\2i\\incomplete\\white\",\n",
    "    mask_type='freeform'  # or 'random_patches', 'center_block', etc.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d543cd81",
   "metadata": {},
   "source": [
    "## CNN Model Training Pipeline\n",
    "Implements a 3-layer CNN (32→64→128 filters) with binary classification for complete vs incomplete image detection.\n",
    "Uses ImageDataGenerator for data preprocessing (rescaling, train/validation split) and trains for 10 epochs.\n",
    "Achieves high training accuracy (99%+) with validation accuracy around 85%, indicating good learning with some overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a17fdd1-1347-45a6-ae0f-b46671700686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12335 images belonging to 2 classes.\n",
      "Found 3083 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skand\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\skand\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 737ms/step - accuracy: 0.7541 - loss: 0.5291 - val_accuracy: 0.7275 - val_loss: 0.5390\n",
      "Epoch 2/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 805ms/step - accuracy: 0.8858 - loss: 0.2684 - val_accuracy: 0.7671 - val_loss: 0.6084\n",
      "Epoch 3/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 691ms/step - accuracy: 0.9578 - loss: 0.1277 - val_accuracy: 0.7691 - val_loss: 0.7252\n",
      "Epoch 4/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 814ms/step - accuracy: 0.9709 - loss: 0.0823 - val_accuracy: 0.7551 - val_loss: 0.9562\n",
      "Epoch 5/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 745ms/step - accuracy: 0.9792 - loss: 0.0612 - val_accuracy: 0.8310 - val_loss: 0.5103\n",
      "Epoch 6/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 733ms/step - accuracy: 0.9840 - loss: 0.0455 - val_accuracy: 0.7859 - val_loss: 0.7684\n",
      "Epoch 7/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 857ms/step - accuracy: 0.9848 - loss: 0.0431 - val_accuracy: 0.7733 - val_loss: 1.2895\n",
      "Epoch 8/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 1s/step - accuracy: 0.9841 - loss: 0.0492 - val_accuracy: 0.8411 - val_loss: 0.7113\n",
      "Epoch 9/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 625ms/step - accuracy: 0.9895 - loss: 0.0302 - val_accuracy: 0.8015 - val_loss: 0.8997\n",
      "Epoch 10/10\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 681ms/step - accuracy: 0.9904 - loss: 0.0252 - val_accuracy: 0.8505 - val_loss: 0.6931\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Image size and batch\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Define dataset directory structure\n",
    "DATA_DIR = r\"C:\\Users\\skand\\Downloads\\2i\"\n",
    "TRAIN_DIR = DATA_DIR  # It has complete/ and incomplete/ folders\n",
    "\n",
    "# Data generators\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Simple CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=10,\n",
    "    validation_data=val_gen\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca576885",
   "metadata": {},
   "source": [
    "## Saving Trained Model\n",
    "Saves the trained model in Keras format (.keras) for future use without retraining.\n",
    "Preserves complete model including architecture, weights, and compilation settings for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ae4d047-53d4-4f5d-a28e-6df1176d3466",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r\"C:\\Users\\skand\\Downloads\\2i\\incomplete_image_detector1.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4bd620",
   "metadata": {},
   "source": [
    "## Single Image Inference Example\n",
    "Demonstrates practical usage by loading a test image, preprocessing it (resize to 128x128, normalize), and making predictions.\n",
    "Model correctly identifies the test image as \"INCOMPLETE\" showing successful deployment capability.\n",
    "Preprocessing pipeline matches training requirements for consistent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93053f14-b52e-4609-a7ec-8348c12d831d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
      " Image is INCOMPLETE (has missing regions).\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Replace this with your image path\n",
    "image_path = r\"cnn_based/sample_images/incomplete/247.jpg\"\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(r\"cnn_based/models/incomplete_image_detector1.keras\")\n",
    "\n",
    "#  Load and preprocess the image\n",
    "img = Image.open(image_path).convert(\"RGB\")\n",
    "img = img.resize((128, 128))  # use same size as training\n",
    "img_array = np.array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "#  Make prediction\n",
    "prediction = model.predict(img_array)[0][0]\n",
    "\n",
    "#  Display result\n",
    "if prediction > 0.5:\n",
    "    print(\" Image is INCOMPLETE (has missing regions).\")\n",
    "else:\n",
    "    print(\" Image is COMPLETE.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab798e13",
   "metadata": {},
   "source": [
    "## Loading Independent Test Dataset\n",
    "Prepares separate test data (554 images) with same preprocessing as training but no shuffling.\n",
    "Uses independent test directory to ensure unbiased evaluation and prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49746d61-5d66-48bc-9c5d-1b99f10655eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 554 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\skand\\Downloads\\1t\",        # path to your test folder\n",
    "    target_size=(128, 128),\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc53aa1",
   "metadata": {},
   "source": [
    "## Final Performance Assessment\n",
    "Evaluates model on independent test set achieving 81% accuracy with reasonable loss values.\n",
    "Results validate the model's readiness for practical incomplete image detection applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d607d26-a1c7-4863-a2d3-8afb8a847077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skand\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 766ms/step - accuracy: 0.9300 - loss: 0.4342\n",
      "Test Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_gen)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
